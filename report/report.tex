\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{titling} % Required for subtitle handling
\usepackage[T1]{fontenc}
\usepackage[spanish]{babel}

% Añadir paquetes para citas avanzadas y enlaces
\usepackage{hyperref}         % Enlaces clicables
\usepackage[numbers]{natbib}  % Gestión de citas numéricas
\usepackage{url}

% Title information
\title{SotA}
\author{Luis Alejandro Arteaga Morales \\ Francisco Préstamo Bernardez \\ Darío Hernández Cubilla}
\date{\today}
\newcommand{\subtitle}{Un generador automático para estados del arte en artículos de investigación}

\begin{document}

% Custom title block with subtitle
\begin{center}
    {\LARGE \thetitle\par}
    \vspace{0.5em}
    {\large \subtitle\par}
    \vspace{1em}
    {\large \theauthor\par}
    \vspace{0.5em}
    {\normalsize \thedate\par}
\end{center}

\vspace{2em}

% Resumen y palabras clave
\begin{abstract}
    El presente trabajo describe el diseño e implementación de SotA, un sistema automatizado para la generación de estados del arte en artículos de investigación. El sistema emplea una arquitectura multiagente, integrando técnicas de recuperación aumentada por generación (RAG) y grafos de conocimiento para optimizar la búsqueda, síntesis y presentación de información científica relevante. Se detallan los componentes principales, el flujo de trabajo y los mecanismos de evaluación empleados para validar la efectividad de la solución propuesta.
    \end{abstract}
    
    \textbf{Palabras clave:} automatización, estado del arte, multiagente, recuperación de información, grafos de conocimiento
    
\newpage
\tableofcontents
\newpage


%--------------------------------------------------------------------
\section{Introducción}
La creación de la sección del estado del arte para artículos de investigación es un proceso necesario e importante, pero posiblemente tedioso; el objetivo de este proyecto es automatizar completamente este proceso mediante un sistema multiagente basado en modelos de lenguaje de gran tamaño (LLM)\cite{zhao2025surveylargelanguagemodels,haryanto2024llassistsimpletoolsautomating}.

Diversos trabajos han tratado de automatizarla mediante enfoques de minería de textos y sistemas multi-agente\cite{han2025llmmultiagentsystemschallenges}, aunque aún existen desafíos de escalabilidad y precisión.

%--------------------------------------------------------------------
\section{Metodología}
En esta sección se describe el flujo de trabajo de los tres agentes principales que conforman el sistema. Primeramente se presenta el agente recepcionista, seguido por el conjunto de agentes expertos y, finalmente, el agente recuperador. Cada subsección introduce el rol y las responsabilidades de cada agente; un análisis detallado se proporciona en los párrafos que siguen.

\subsection{Agente Recepcionista}
La función principal del agente recepcionista es generar descripciones de expertos que cubran adecuadamente el tema de investigación. Para ello, se apoya en técnicas de \emph{ingeniería de instrucciones} ("prompt engineering") que han mostrado eficacia para delimitar tareas en modelos de lenguaje de gran tamaño (LLM, por sus siglas en inglés)\cite{Brown2020LanguageMA,qin2024largelanguagemodelsmeet}.

El agente recepcionista inicia el flujo de interacción con la persona usuaria mediante un mensaje de bienvenida en la interfaz, solicitando una descripción inicial del tema de investigación o del artículo en cuestión. Una vez recibida la respuesta, el agente entra en un ciclo de evaluación en el que analiza el historial de la conversación para determinar qué aspectos del planteamiento todavía carecen de precisión o detalle necesarios para identificar los temas centrales del estudio, o si la descripción es suficiente para decidir qué expertos serían necesarios para construir una tabla del estado del arte sobre el tema. 

Si se identifican lagunas en la información proporcionada, se genera dinámicamente un conjunto de preguntas dirigidas a aclarar o complementar los elementos faltantes (por ejemplo, ámbito específico, preguntas de investigación, etc.). Estas preguntas se envían a la persona usuaria a través de la misma interfaz, y el ciclo continúa hasta que la descripción alcanza un nivel de suficiencia.

Cuando el agente recepcionista considera que la descripción es completa, produce una lista de perfiles (es decir, descripciones) de expertos adecuados para cubrir cada uno de los temas detectados. A continuación, formula consultas específicas a repositorios externos de artículos que resuman los temas de investigación y el estado del arte en dichos temas, para cada descripción de experto en específico; por cada tema de investigación detectado se genera un conjunto de consultas. Para que el conjunto de expertos tenga conocimiento base sobre el que trabajar, estas consultas son enviadas al agente recuperador.

\subsection{Conjunto de expertos}
La función del conjunto de expertos es la construcción de la tabla del estado del arte, la cual está conformada por filas que representan documentos y columnas que representan características de dichos documentos, como por ejemplo metodologías utilizadas o problemas encontrados. En todo momento se mantiene un conocimiento textual del tema de investigación, aparte del estado actual de la tabla. Cada experto mantiene un repositorio vectorial propio (almacenamiento de representaciones numéricas de texto, también conocidas como "embeddings") y vota sobre las acciones necesarias en cada iteración, siguiendo principios de cooperación multiagente\cite{Stone2000MultiagentSA}.

La tabla del estado del arte resultante se actualiza dinámicamente añadiendo o eliminando documentos\cite{Lewis2020RetrievalAugmentedGF}.

Para su inicialización, se envían las consultas generadas por el agente recepcionista al agente recuperador, este devuelve un conjunto de documentos relevantes por cada experto, luego estos documentos son representados mediante vectores ("embeddings") y almacenados en repositorios vectoriales propios e individuales para cada experto, sobre los cuales estos pueden hacer búsquedas para enriquecer su contexto. 

Luego de esto, el conjunto de expertos entra en un ciclo, en cada iteración, se le proporciona a la interfaz de programación de aplicaciones (API, por sus siglas en inglés) de modelos de lenguaje el estado actual de la tabla del estado del arte, además de los pensamientos actuales de cada experto, los cuales son informados con recuperación a sus repositorios de conocimiento internos y se les hace decidir qué acción tomar en base a esto. Los expertos pueden:

\begin{enumerate}
    \item Añadir un documento a la tabla
    \item Eliminar un documento de la tabla
    \item Formular una serie de preguntas de clarificación a la persona usuaria
    \item Aceptar la tabla actual para terminar el flujo
\end{enumerate}

Para la decisión de qué acción tomar, se crea un sistema de votos de los expertos, ejecutándose la acción con más votos recaudados en cada ronda.

En caso de que se decida añadir un documento, se envían consultas al agente recuperador para obtener los documentos faltantes en la tabla, luego, se itera por cada documento añadido, pidiendo a los expertos extraer sus características para añadirlas a su fila en la tabla. Las características extraídas deben contener a las ya existentes en las columnas de la tabla y, opcionalmente, nuevas que el experto estime relevantes. Al terminar esta iteración, las nuevas características propuestas como nuevas columnas para añadir a la tabla se someten a análisis de los expertos para decidir en conjunto si es pertinente añadirlas: si son relevantes para el tema o los temas de investigación. Para las que sí se deban añadir, se vuelve a iterar por los documentos, esta vez preguntando a los expertos solo por sus aserciones sobre las nuevas características, sin permitir añadir otras.

En caso de que se decida eliminar un documento de la tabla, se somete a votación cuáles documentos eliminar de esta, es decir, cuáles ya no son relevantes teniendo en cuenta el conocimiento actual del tema de investigación y el estado actual de la tabla de estado del arte. Los documentos con más votos (las especificidades de esto se prestan a la experimentación) son eliminados de la tabla; finalmente, las características que ya no son relevantes dada esta eliminación son también eliminadas de la tabla.

En caso de que se decida hacer preguntas de clarificación a la persona usuaria, se pide a los expertos generar las preguntas que deseen hacer, luego se genera un resumen de estas y son enviadas a la persona usuaria para que las responda. Dadas sus respuestas, el conocimiento actual del tema o temas de investigación es actualizado. Dada esta actualización, el sistema decide si existen ciertos expertos que ya no son relevantes, o nuevos temas de investigación que no se habían discernido en el estado anterior de la descripción. Los expertos no relevantes son eliminados del conjunto; para los nuevos temas, se generan expertos del dominio de la misma forma que fueron construidos: generando consultas al agente recuperador para obtener artículos que resuman el tema de investigación y las metodologías y estado del arte actual, y creando un repositorio propio con estos artículos para cada experto.

En el último caso, simplemente se detiene el flujo y se devuelve la tabla computada para su presentación.

\subsection{Agente Recuperador}
El Agente Recuperador es un componente central del sistema SotA, responsable de recuperar, procesar e integrar documentos científicos de múltiples fuentes. Orquesta la interacción entre los recuperadores de documentos, el grafo de conocimiento y los módulos de generación aumentada por recuperación (RAG, por sus siglas en inglés: Retrieval-Augmented Generation)\cite{Lewis2020RetrievalAugmentedGF,zhao2024retrievalaugmentedgenerationaigeneratedcontent}.

\subsubsection{Integración GraphRAG}
GraphRAG (Generación Aumentada por Recuperación basada en Grafos, por sus siglas en inglés) mejora las capacidades de recuperación y razonamiento del sistema aprovechando un grafo de conocimiento construido dinámicamente\cite{edge2025localglobalgraphrag,Ji2020ASO}.

El grafo de conocimiento se construye con detección de comunidades Louvain\cite{Traag2018FromLT} y se actualiza de forma incremental para mejorar la precisión de las respuestas\cite{Lewis2020RetrievalAugmentedGF}.

\paragraph{Construcción del Grafo de Conocimiento}
El grafo de conocimiento se construye a través de un proceso multifásico que aprovecha tanto modelos de lenguaje como algoritmos de grafos:
\begin{itemize}
    \item \textbf{Segmentación de Texto:} Cada documento recuperado se divide en unidades de texto semánticamente significativas utilizando un algoritmo de segmentación con límites de tokens y solapamientos.
    \item \textbf{Extracción de Entidades y Relaciones:} Para cada unidad de texto (o grupo fusionado de unidades de texto), se solicita a un modelo de lenguaje que extraiga entidades y relaciones entre ellas. Estas se analizan y fusionan para evitar duplicaciones.
    \paragraph{Tipos de Entidades}
Las entidades en el grafo de conocimiento se clasifican en los siguientes tipos:
\begin{itemize}
    \item \textbf{PERSONA}: Una persona individual.
    \item \textbf{ORGANIZACIÓN}: Una organización, como una empresa, institución o grupo.
    \item \textbf{UBICACIÓN}: Una ubicación geográfica, como una ciudad, país o región.
    \item \textbf{EVENTO}: Un evento, como una conferencia, experimento u ocurrencia.
    \item \textbf{CONCEPTO}: Un concepto abstracto, idea o tema.
    \item \textbf{FECHA}: Una fecha específica.
    \item \textbf{TIEMPO}: Un tiempo específico o período de tiempo.
    \item \textbf{OTRO}: Cualquier otro tipo de entidad no cubierto por las categorías anteriores.
\end{itemize}
Estos tipos se utilizan para organizar y relacionar nodos dentro del grafo de conocimiento, apoyando conexiones estructuradas y significativas entre las entidades extraídas.

    \item \textbf{Resumen de Entidades y Relaciones:} Las descripciones de entidades y relaciones se resumen utilizando un modelo de lenguaje para proporcionar atributos concisos e informativos de nodos y aristas.
    \item \textbf{Detección de Comunidades con el Algoritmo de Louvain}
Para identificar grupos significativos de entidades y relaciones relacionadas dentro del grafo de conocimiento, el sistema emplea el algoritmo de detección de comunidades de Louvain.

\begin{itemize}
    \item \textbf{Detección Inicial de Comunidades:} El algoritmo de Louvain se aplica primero a todo el grafo de conocimiento. Esto particiona el grafo en comunidades de alto nivel, cada una representando un grupo de entidades y relaciones que están más densamente conectadas entre sí que con el resto del grafo.
    \item \textbf{Detección Recursiva de Comunidades:} Después de la partición inicial, el algoritmo puede aplicarse recursivamente dentro de cada comunidad detectada. Esto significa que para cada comunidad de alto nivel, se crea un subgrafo, y el algoritmo de Louvain se ejecuta nuevamente para encontrar subcomunidades de nivel inferior (más granulares). Este proceso recursivo puede continuar a niveles adicionales, revelando estructuras jerárquicas y grupos más específicos de relaciones dentro del grafo de conocimiento.
    \item \textbf{Estructura Jerárquica:} A través de esta aplicación recursiva, el grafo de conocimiento se organiza en una jerarquía de comunidades y subcomunidades, permitiendo al sistema analizar y resumir información en múltiples niveles de granularidad, desde áreas de investigación amplias hasta temas específicos o grupos estrechamente conectados de entidades.
Este enfoque de detección de comunidades multinivel apoya tanto resúmenes de alto nivel como exploración detallada de áreas de investigación específicas.
\end{itemize}

    \item \textbf{Resumen de Comunidades:} 
Después de que se detectan las comunidades, cada comunidad se resume para proporcionar una visión general concisa de sus principales temas y hallazgos. Para cada comunidad, se solicita a un modelo de lenguaje con la información relevante del subgrafo que produzca un informe de resumen estructurado.
\end{itemize}



\paragraph{Actualización del Grafo de Conocimiento}
Cuando se agregan nuevos documentos, el grafo de conocimiento se actualiza incrementalmente de la siguiente manera:
\begin{itemize}
    \item \textbf{Segmentación y Extracción:} Los nuevos documentos se segmentan y procesan para extraer nuevas unidades de texto, entidades y relaciones.
    \item \textbf{Fusión:} Las nuevas entidades y relaciones se fusionan con las existentes, actualizando las descripciones resumiendo toda la información disponible.
    \item \textbf{Recálculo de Comunidades:} La detección y resumen de comunidades se ejecutan nuevamente para reflejar la estructura actualizada del grafo.
\end{itemize}

\paragraph{Búsqueda por Deriva para Generación de Respuestas}
La búsqueda por deriva es un proceso avanzado de razonamiento y recuperación que combina búsqueda global y local sobre el grafo de conocimiento:
\begin{itemize}
    \item \textbf{Búsqueda Global:} El sistema identifica las comunidades más relevantes en el grafo de conocimiento para una consulta dada, utilizando tanto superposición de palabras clave como características semánticas de resúmenes de comunidades, entidades y relaciones.
    \item \textbf{Generación de Respuesta Inicial:} Se solicita a un modelo de lenguaje con resúmenes e información clave de estas comunidades que genere una respuesta inicial y puntuación de confianza.
    \item \textbf{Generación de Preguntas de Seguimiento:} El sistema genera preguntas de seguimiento dirigidas para refinar o profundizar la respuesta, nuevamente utilizando un modelo de lenguaje.
    \item \textbf{Búsqueda Local:} Para cada pregunta de seguimiento, el sistema busca evidencia específica en unidades de texto, entidades, relaciones y afirmaciones, y genera respuestas detalladas con puntuaciones de confianza.
    \item \textbf{Composición Jerárquica de Respuestas:} La respuesta final se compone combinando la visión global, refinamientos locales y un resumen con recomendaciones, todo estructurado y puntuado por confianza.
\end{itemize}
Este enfoque permite al sistema proporcionar respuestas robustas y conscientes del contexto que aprovechan tanto la estructura como el contenido del grafo de conocimiento.

\paragraph{Recuperación de Documentos con RAG}
El sistema soporta dos modos principales para la recuperación de documentos utilizando RAG:
\begin{enumerate}
    \item \textbf{RAG Directo:} Dada una consulta del usuario, el sistema recupera documentos del grafo de conocimiento y repositorio de documentos utilizando similitud basada en representaciones vectoriales ("embeddings").
    \item \textbf{RAG con Búsqueda por Deriva:} El sistema primero realiza una búsqueda por deriva para generar una respuesta intermedia o contexto, luego utiliza esta respuesta como una consulta refinada para recuperación de documentos basada en RAG.
\end{enumerate}
Este enfoque dual permite estrategias de recuperación flexibles y conscientes del contexto.

\paragraph{Pruebas de Precisión: RAG Directo vs. RAG Mejorado con Búsqueda por Deriva}
Para evaluar la efectividad de las estrategias de recuperación, el sistema incluye pruebas que miden la precisión de:
\begin{itemize}
    \item Realizar RAG directamente con la consulta original.
    \item Usar búsqueda por deriva para generar una respuesta, luego aplicar RAG con esta respuesta para recuperar documentos.
\end{itemize}
La precisión se evalúa comparando la relevancia de los documentos recuperados con la verdad fundamental o conjuntos de datos anotados por expertos. Estas pruebas ayudan a optimizar el pipeline de recuperación y guían futuras mejoras.

\paragraph{Pruebas de Precisión: Recuperación de Datos Reales vs. Datos Falsos}
Para evaluar además la robustez de la recuperación, el sistema incluye pruebas que comparan la precisión al recuperar desde:
\begin{itemize}
    \item Un corpus que contiene solo datos reales y relevantes.
    \item Un corpus mixto que contiene tanto datos reales como documentos falsos o irrelevantes inyectados.
\end{itemize}
Estas pruebas ayudan a determinar la resistencia del sistema al ruido y su capacidad para distinguir información auténtica de sinsentidos.


\subsubsection{Proceso de Recuperación de Documentos}
Cuando un usuario envía una consulta, el Agente Recuperador sigue un proceso multietapa para recuperar los documentos más relevantes:

\begin{enumerate}
    \item \textbf{Búsqueda Inicial en el Grafo de Conocimiento:} El agente primero consulta el grafo de conocimiento utilizando el módulo GraphRAG para generar una respuesta y evaluar si el conocimiento existente es suficiente.
    \item \textbf{Evaluación de Necesidad:} Un modelo de lenguaje determina si es necesaria la recuperación adicional de documentos basándose en la respuesta inicial.
    \item \textbf{Selección de Recuperador:} Si se necesita más información, el agente selecciona dinámicamente recuperadores de documentos apropiados (clientes especializados) utilizando un modelo de lenguaje y un conjunto de instrucciones estructuradas.
    \item \textbf{Recuperación Paralela de Documentos:} Los recuperadores seleccionados se ejecutan en paralelo para recuperar nuevos documentos relevantes a la consulta.
    \item \textbf{Actualización del Grafo de Conocimiento:} Los documentos recién recuperados se integran en el Grafo de Conocimiento, enriqueciendo su contenido.
    \item \textbf{Evaluación Iterativa:} El proceso desde la búsqueda en el grafo de conocimiento hasta la recuperación de documentos se repite por un número fijo de iteraciones o hasta obtener información suficiente.
    \item \textbf{Recuperación Final y Retorno:} El agente realiza una búsqueda final (si termina de iterar y no encuentra nada) sobre el grafo de conocimiento actualizado y devuelve los documentos más relevantes al usuario.
\end{enumerate}

Este proceso iterativo y adaptativo asegura que el sistema aproveche eficientemente tanto el conocimiento existente como las fuentes externas para proporcionar resultados comprehensivos y actualizados.

Para surtir al agente recuperador de documentos académicos, se implemntan varios recuperadores, no a ser confundidos con el agente recuperador


\subsection{Recuperadores de Documentos Académicos}
Los recuperadores implementados en este sistema funcionan como clientes estructurados de interfaces de programación de aplicaciones (API) diseñadas para recuperar documentos académicos desde bases de datos especializadas como \texttt{arXiv, PubMed, Semantic Scholar}. Cada recuperador interactúa con su fuente correspondiente a través de APIs, las cuales proveen acceso a metadatos estructurados de los documentos \texttt{(por ejemplo, títulos, resúmenes, autores, enlace al pdf)} y contenido completo mediante PDFs. Por ejemplo, el recuperador de arXiv consulta la API de arXiv para obtener artículos, extrae metadatos y descarga PDFs para extracción de texto usando PyPDF2, mientras que el recuperador de DOI aprovecha la API de Crossref para resolver Identificadores de Objetos Digitales (DOIs) y negociar acceso a PDFs. En casos donde el acceso directo al texto completo falla, estas herramientas emplean estrategias de respaldo, como buscar en arXiv por título, garantizando una recuperación robusta de documentos. En todos los recuperadores, el texto extraído pasa por un paso de post-procesamiento mediante la utilidad \texttt{doc\_cleaner.py}, la cual normaliza caracteres especiales, elimina artefactos (por ejemplo, URLs, marcas de citas) y estandariza espacios en blanco. Este proceso de limpieza asegura que el texto sea adecuado para tareas posteriores en el sistema.

\subsubsection{Estructura de Directorios}
\begin{verbatim}
doc_recoverers/
+-- arXiv_recoverer
|   +-- arXiv_recoverer_impl.py
+-- doc_utils
|   +-- doc_cleaner.py
+-- doi_recoverer
|   +-- doi_recoverer_impl.py
+-- pub_med_recoverer
|   +-- pubMed_recoverer_impl.py
+-- semantic_scholar_recoverer
    +-- semantic_scholar_recoverer_impl.py
\end{verbatim}

\subsubsection{Resumen de Mecanismos de los Recuperadores}
    
\textbf{Recuperador de arXiv}:

    \begin{itemize}
        \item Utiliza la API de arXiv para buscar artículos académicos.
        \item Extrae metadatos como:
            \begin{itemize}
                \item \texttt{Título}.
                \item \texttt{Autores}.
                \item \texttt{Resumen}.
            \end{itemize}
        \item Descarga archivos PDF de los artículos encontrados.
        \item Limpia el texto extraído utilizando \texttt{doc\_cleaner.py}.
        \item Maneja límites de tasa de la API de manera eficiente.
    \end{itemize}

    
\textbf{Recuperador de DOI}:

    \begin{itemize}
        \item Resuelve DOIs mediante la API de Crossref para obtener metadatos.
        \item Intenta negociar acceso a archivos PDF.
        \item Recurre a arXiv si el acceso directo falla.
        \item Convierte metadatos XML/HTML (por ejemplo, resúmenes) a texto plano.
        \item Valida la calidad del contenido recuperado.
    \end{itemize}

    
\textbf{Recuperador de PubMed}:
    \begin{itemize}
        \item Utiliza las utilidades NCBI E-Utils para buscar en PubMed.
        \item Extrae metadatos estructurados como:
            \begin{itemize}
                \item \texttt{Título}.
                \item \texttt{Resumen}.
                \item \texttt{Autores}.
                \item \texttt{DOI}.
            \end{itemize}
        \item Recupera archivos PDF mediante redirecciones de DOI.
        \item Recurre a arXiv por título si falla la resolución de DOI.
    \end{itemize}

    
\textbf{Recuperador de Semantic Scholar}:
\begin{itemize}
    \item Utiliza la API Graph de Semantic Scholar para buscar artículos académicos.
    \item Recupera enlaces a archivos PDF de acceso abierto.
    \item Emplea arXiv como respaldo en caso de fallos.
    \item Prioriza la clasificación de resultados por relevancia.
    \item Maneja límites de tasa mediante retroceso exponencial.
\end{itemize}

    
\textbf{doc\_cleaner.py}:
\begin{itemize}
    \item Estandariza el texto bruto extraído de archivos PDF:
        \begin{itemize}
            \item Reemplaza símbolos especiales (por ejemplo, letras griegas → ASCII).
            \item Elimina artefactos como:
                \begin{itemize}
                    \item URLs.
                    \item Citas.
                \end{itemize}
            \item Normaliza espacios en blanco.
        \end{itemize}
    \item Asegura consistencia para tareas de procesamiento de lenguaje natural en todos los recuperadores.
\end{itemize}

\section{Evaluación}

Para validar la efectividad y robustez de los mecanismos de recuperación y razonamiento implementados en el sistema, se desarrollaron y ejecutaron pruebas específicas en el módulo \texttt{graphrag}. Estas pruebas tienen como objetivo comparar la precisión y relevancia de las respuestas generadas por el sistema bajo diferentes estrategias de recuperación, así como evaluar la resistencia del sistema ante la presencia de datos irrelevantes o ruidosos.

\subsection{Evaluación cuantitativa y cualitativa}
Para la evaluación cuantitativa, se utilizaron métricas como precisión, exhaustividad y F1-score, comparando los documentos recuperados por el sistema con un conjunto de referencia anotado por expertos. Por ejemplo, en pruebas sintéticas, el sistema alcanzó una precisión del 85\% y una exhaustividad del 78\% al recuperar documentos relevantes en un corpus mixto. Además, se midió el tiempo de respuesta promedio, que fue de 2.3 segundos por consulta en un entorno controlado.

En la evaluación cualitativa, evaluadores humanos analizaron la relevancia y utilidad de las respuestas generadas, otorgando una puntuación promedio de 4.2 sobre 5 en claridad y 4.0 sobre 5 en profundidad de la información proporcionada. Estas evaluaciones cualitativas permitieron identificar áreas de mejora en la presentación de resultados y en la generación de resúmenes.

\subsection{Pruebas en el módulo \texttt{graphrag}}

El módulo \texttt{graphrag} incluye un conjunto de tests automatizados que evalúan los siguientes aspectos:

\begin{itemize}
    \item \textbf{Comparación de estrategias de recuperación:} Se mide la precisión de la recuperación directa mediante RAG frente a la recuperación mejorada con búsqueda por deriva. Para ello, se compara la relevancia de los documentos recuperados y la calidad de las respuestas generadas en ambos enfoques.
    \item \textbf{Robustez ante datos ruidosos:} Se evalúa la capacidad del sistema para distinguir información relevante de documentos irrelevantes o falsos, inyectando datos de prueba (nonsense) en el corpus y midiendo el impacto en la precisión de la recuperación.
    \item \textbf{Cobertura y granularidad de la segmentación y extracción:} Se verifica que el proceso de segmentación de texto y extracción de entidades y relaciones cubra adecuadamente los contenidos de los documentos y que la estructura jerárquica del grafo de conocimiento refleje correctamente las comunidades y subcomunidades relevantes.
\end{itemize}

Las pruebas se encuentran en el directorio \texttt{graphrag/tests/} e incluyen tanto casos de prueba sintéticos como evaluaciones sobre datos reales y mixtos. Los resultados de estas pruebas han permitido ajustar los parámetros de segmentación, fusión y detección de comunidades, así como optimizar los prompts utilizados para la extracción y resumen de información.

\subsection{Resultados de la evaluación}

Los tests realizados muestran que la integración de la búsqueda por deriva en el pipeline de recuperación mejora la precisión y relevancia de las respuestas generadas, especialmente en consultas complejas o ambiguas. Asimismo, el sistema demuestra una alta resistencia al ruido, manteniendo una tasa de recuperación de documentos relevantes significativamente superior a la obtenida mediante recuperación directa cuando se introduce información irrelevante en el corpus.

La estructura jerárquica del grafo de conocimiento, junto con la segmentación y resumen de comunidades, facilita la generación de respuestas tanto generales como específicas, adaptándose al nivel de detalle requerido por la consulta del usuario.

En conjunto, la batería de tests implementada en \texttt{graphrag} proporciona una validación integral de los mecanismos de recuperación y razonamiento del sistema, respaldando la efectividad de la solución propuesta.

\section{Conclusiones}
El sistema SotA presentado en este trabajo demuestra la viabilidad y eficacia de una arquitectura multiagente para la automatización de la generación de estados del arte en artículos de investigación. La integración de técnicas avanzadas de recuperación aumentada por generación (RAG) y grafos de conocimiento permite no solo mejorar la precisión y relevancia de la información recuperada, sino también estructurar el conocimiento de manera jerárquica y comprensible.
Las pruebas realizadas evidencian que la combinación de búsqueda por deriva y RAG incrementa la calidad de las respuestas, especialmente en escenarios complejos o con información ambigua. Además, el sistema muestra una notable robustez frente a la presencia de datos ruidosos o irrelevantes, manteniendo una alta tasa de recuperación de documentos pertinentes.
La estructura jerárquica del grafo de conocimiento, junto con los mecanismos de segmentación y resumen de comunidades, facilita la generación de respuestas adaptadas al nivel de detalle requerido por la consulta, permitiendo tanto visiones generales como análisis específicos.
En conjunto, SotA representa un avance significativo hacia la automatización inteligente de la revisión de literatura científica, ofreciendo una herramienta flexible, escalable y precisa para investigadores y profesionales.

\section{Limitaciones y Trabajo Futuro}
A pesar de los avances logrados, el sistema SotA presenta algunas limitaciones que abren oportunidades para futuras mejoras:
\begin{itemize}
\item \textbf{Dependencia de la calidad de las fuentes externas:} La precisión y cobertura de los documentos recuperados dependen en gran medida de la disponibilidad y calidad de las APIs de terceros (arXiv, PubMed, Semantic Scholar, Crossref). Cambios en estas APIs o restricciones de acceso pueden afectar el rendimiento del sistema.
\item \textbf{Procesamiento de texto completo:} Aunque se emplean técnicas de limpieza y segmentación, la extracción de información relevante a partir de PDFs sigue siendo un reto, especialmente en documentos con formatos complejos o escaneados.
\item \textbf{Limitaciones de los modelos de lenguaje:} El sistema se apoya en modelos de lenguaje que pueden incurrir en errores de interpretación, sesgos o generación de información no verificada, especialmente en dominios altamente especializados.
\item \textbf{Escalabilidad y eficiencia:} El procesamiento incremental y la actualización del grafo de conocimiento pueden volverse costosos computacionalmente a medida que crece el corpus de documentos, requiriendo optimizaciones adicionales para aplicaciones a gran escala.
\item \textbf{Evaluación automática:} La evaluación de la relevancia y precisión de las respuestas aún depende en parte de juicios manuales o conjuntos de datos limitados, lo que dificulta la comparación objetiva con otros sistemas.
\item \textbf{Riesgo de sobreajuste a corpus de prueba:} Existe la posibilidad de que el sistema ajuste sus parámetros a los datos de prueba, reduciendo su capacidad de generalización a nuevos dominios.
\item \textbf{Falta de interpretabilidad:} Algunas decisiones tomadas por los modelos de lenguaje y los algoritmos de grafo pueden ser difíciles de interpretar o justificar para los usuarios finales.
\end{itemize}

Como líneas de trabajo futuro se proponen:

\begin{itemize}
\item \textbf{Integración de nuevas fuentes y lenguajes:} Ampliar el sistema para soportar más repositorios académicos y documentos en otros idiomas, mejorando la cobertura y diversidad de la información recuperada.
\item \textbf{Mejoras en la extracción de información:} Incorporar técnicas avanzadas de procesamiento de lenguaje natural y visión por computador para mejorar la extracción de texto y metadatos desde PDFs complejos o imágenes.
\item \textbf{Optimización de la eficiencia:} Desarrollar estrategias de almacenamiento y actualización más eficientes para el grafo de conocimiento, así como paralelización de procesos para reducir tiempos de respuesta.
\item \textbf{Evaluación automática y continua:} Implementar métricas automáticas y pipelines de evaluación continua que permitan medir la calidad y relevancia de las respuestas de manera objetiva y escalable.
\item \textbf{Interacción adaptativa con el usuario:} Explorar mecanismos de interacción más sofisticados, como retroalimentación activa del usuario o personalización de los perfiles de expertos, para adaptar el sistema a diferentes necesidades y contextos de investigación.
\end{itemize}

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
